{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRzemqK4Pppn",
        "outputId": "753d46b8-2e4c-4b85-822e-15038b8e6f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjgPvOmUOmVM",
        "outputId": "a9c4b20e-4fe7-42a9-ab09-9bfd78b843b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/diffusers\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-az4g0xha\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-az4g0xha\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 56b3b216936affc398220c8e8e49ceba5db7bf9a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (7.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.25.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.25.0.dev0-py3-none-any.whl size=1822296 sha256=0d6cc989d30d83432b0ae7b872124011291c58882d32c8c318a8c7f6047d81b7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w49r1xj0/wheels/f7/7d/99/d361489e5762e3464b3811bc629e94cf5bf5ef44dd5c3c4d52\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.25.0.dev0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers\n",
        "!pip install -qq accelerate transformers ftfy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "id": "Hm0fM_paP0bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd40e5ef-3fff-4805-eb8c-2a33ac33c0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install xformers\n",
        "%pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPJ-kaXK53Wd",
        "outputId": "4f0a5fba-3bb0-4cea-d33e-03b708cd1045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Collecting torch==2.1.2 (from xformers)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (2023.6.0)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->xformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->xformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 xformers-0.0.23.post1\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.3.post2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFPsjGE179IG",
        "outputId": "7995d9f1-5d90-436a-f9c9-c5ce31a2f1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-18 09:16:21--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57625 (56K) [text/plain]\n",
            "Saving to: ‘train_dreambooth.py’\n",
            "\n",
            "\rtrain_dreambooth.py   0%[                    ]       0  --.-KB/s               \rtrain_dreambooth.py 100%[===================>]  56.27K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-12-18 09:16:22 (5.18 MB/s) - ‘train_dreambooth.py’ saved [57625/57625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
        "# MODEL_NAME=\"stabilityai/stable-diffusion-2-base\"\n",
        "# INSTANCE_DIR=\"/content/drive/MyDrive/DL_Project/kungfu\"\n",
        "# OUTPUT_DIR=\"./dreambooth-out2/\"\n",
        "# CLASS_DIR=\"/content/drive/MyDrive/DL_Project/kungfu_class\"\n",
        "\n",
        "# !accelerate launch train_dreambooth.py \\\n",
        "#   --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
        "#   --train_text_encoder \\\n",
        "#   --instance_data_dir=$INSTANCE_DIR \\\n",
        "#   --output_dir=$OUTPUT_DIR \\\n",
        "#   --instance_prompt=\"a photo of sks panda\" \\\n",
        "#   --resolution=512 \\\n",
        "#   --train_batch_size=2 \\\n",
        "#   --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "#   --learning_rate=4e-7 \\\n",
        "#   --lr_scheduler=\"constant\" \\\n",
        "#   --set_grads_to_none \\\n",
        "#   --lr_warmup_steps=0 \\\n",
        "#   --max_train_steps=520 \\\n",
        "#   --enable_xformers_memory_efficient_attention \\\n",
        "#   --use_8bit_adam \\\n",
        "#   --class_data_dir=$CLASS_DIR \\\n",
        "#   --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "#   --class_prompt=\"a photo of panda\" \\\n",
        "#   --num_class_images=800"
      ],
      "metadata": {
        "id": "cXbN6RgXOF0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
        "MODEL_NAME=\"stabilityai/stable-diffusion-2-base\"\n",
        "INSTANCE_DIR=\"/content/drive/MyDrive/DL_Project/kungfu\"\n",
        "OUTPUT_DIR=\"./dreambooth-out2/\"\n",
        "CLASS_DIR=\"/content/drive/MyDrive/DL_Project/kungfu_class\"\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
        "  --train_text_encoder \\\n",
        "  --instance_data_dir=$INSTANCE_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --instance_prompt=\"a photo of sks panda\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "  --learning_rate=0.001 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --set_grads_to_none \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=520 \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --use_8bit_adam \\\n",
        "  --class_data_dir=$CLASS_DIR \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --class_prompt=\"a photo of panda\" \\\n",
        "  --num_class_images=800"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp6J6isW58f_",
        "outputId": "5799acaf-9894-4e56-95c5-c6002d923163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-18 09:19:09.669324: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-18 09:19:09.669386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-18 09:19:09.670842: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-18 09:19:11.691197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/18/2023 09:19:13 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'thresholding', 'sample_max_value', 'dynamic_thresholding_ratio', 'variance_type', 'clip_sample_range', 'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'mid_block_only_cross_attention', 'num_class_embeds', 'cross_attention_norm', 'encoder_hid_dim', 'upcast_attention', 'addition_time_embed_dim', 'transformer_layers_per_block', 'conv_out_kernel', 'encoder_hid_dim_type', 'time_embedding_type', 'conv_in_kernel', 'resnet_skip_time_act', 'reverse_transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'only_cross_attention', 'class_embeddings_concat', 'time_embedding_act_fn', 'attention_type', 'num_attention_heads', 'timestep_post_act', 'addition_embed_type_num_heads', 'time_embedding_dim', 'mid_block_type', 'class_embed_type', 'addition_embed_type', 'dropout', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'resnet_out_scale_factor'} was not found in config. Values will be initialized to default values.\n",
            "12/18/2023 09:19:50 - INFO - __main__ - ***** Running training *****\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Num examples = 800\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Num batches each epoch = 400\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Num Epochs = 2\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Instantaneous batch size per device = 2\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "12/18/2023 09:19:50 - INFO - __main__ -   Total optimization steps = 520\n",
            "Steps:   0% 0/520 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Steps:  96% 500/520 [43:08<01:42,  5.14s/it, loss=2.01, lr=0.001]12/18/2023 10:02:58 - INFO - accelerate.accelerator - Saving current state to ./dreambooth-out2/checkpoint-500\n",
            "Configuration saved in ./dreambooth-out2/checkpoint-500/unet/config.json\n",
            "Model weights saved in ./dreambooth-out2/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
            "12/18/2023 10:03:50 - INFO - accelerate.checkpointing - Optimizer state saved in dreambooth-out2/checkpoint-500/optimizer.bin\n",
            "12/18/2023 10:03:50 - INFO - accelerate.checkpointing - Scheduler state saved in dreambooth-out2/checkpoint-500/scheduler.bin\n",
            "12/18/2023 10:03:50 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in dreambooth-out2/checkpoint-500/sampler.bin\n",
            "12/18/2023 10:03:50 - INFO - accelerate.checkpointing - Random states saved in dreambooth-out2/checkpoint-500/random_states_0.pkl\n",
            "12/18/2023 10:03:50 - INFO - __main__ - Saved state to ./dreambooth-out2/checkpoint-500\n",
            "Steps: 100% 520/520 [45:43<00:00,  5.14s/it, loss=1.99, lr=0.001]\n",
            "model_index.json: 100% 537/537 [00:00<00:00, 2.51MB/s]\n",
            "\n",
            "Fetching 9 files:   0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 1.29MB/s]\n",
            "\n",
            "Fetching 9 files: 100% 9/9 [00:00<00:00, 38.24it/s]\n",
            "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[A{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-base.\n",
            "\n",
            "Loading pipeline components...:  17% 1/6 [00:00<00:01,  2.87it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-base.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-base.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-base.\n",
            "\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00, 12.38it/s]\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Configuration saved in ./dreambooth-out2/vae/config.json\n",
            "Model weights saved in ./dreambooth-out2/vae/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in ./dreambooth-out2/unet/config.json\n",
            "Model weights saved in ./dreambooth-out2/unet/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in ./dreambooth-out2/scheduler/scheduler_config.json\n",
            "Configuration saved in ./dreambooth-out2/model_index.json\n",
            "Steps: 100% 520/520 [46:30<00:00,  5.37s/it, loss=1.99, lr=0.001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r dreambooth-out1.zip ./dreambooth-out1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRbP6lht7ot0",
        "outputId": "17ab3e15-c7ca-49f9-84e9-76e95f15fe6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: dreambooth-out1/ (stored 0%)\n",
            "  adding: dreambooth-out1/scheduler/ (stored 0%)\n",
            "  adding: dreambooth-out1/scheduler/scheduler_config.json (deflated 41%)\n",
            "  adding: dreambooth-out1/text_encoder/ (stored 0%)\n",
            "  adding: dreambooth-out1/text_encoder/config.json (deflated 45%)\n",
            "  adding: dreambooth-out1/text_encoder/model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/feature_extractor/ (stored 0%)\n",
            "  adding: dreambooth-out1/feature_extractor/preprocessor_config.json (deflated 49%)\n",
            "  adding: dreambooth-out1/checkpoint-500/ (stored 0%)\n",
            "  adding: dreambooth-out1/checkpoint-500/text_encoder/ (stored 0%)\n",
            "  adding: dreambooth-out1/checkpoint-500/text_encoder/config.json (deflated 45%)\n",
            "  adding: dreambooth-out1/checkpoint-500/text_encoder/model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/checkpoint-500/optimizer.bin (deflated 22%)\n",
            "  adding: dreambooth-out1/checkpoint-500/scheduler.bin (deflated 55%)\n",
            "  adding: dreambooth-out1/checkpoint-500/unet/ (stored 0%)\n",
            "  adding: dreambooth-out1/checkpoint-500/unet/config.json (deflated 66%)\n",
            "  adding: dreambooth-out1/checkpoint-500/unet/diffusion_pytorch_model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/checkpoint-500/random_states_0.pkl (deflated 25%)\n",
            "  adding: dreambooth-out1/vae/ (stored 0%)\n",
            "  adding: dreambooth-out1/vae/config.json (deflated 53%)\n",
            "  adding: dreambooth-out1/vae/diffusion_pytorch_model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/logs/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5915463/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5915463/events.out.tfevents.1702825463.cf7b68bcd47c.7904.1 (deflated 56%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5935092/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5935092/hparams.yml (deflated 52%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/events.out.tfevents.1702825463.cf7b68bcd47c.7904.0 (deflated 66%)\n",
            "  adding: dreambooth-out1/model_index.json (deflated 56%)\n",
            "  adding: dreambooth-out1/tokenizer/ (stored 0%)\n",
            "  adding: dreambooth-out1/tokenizer/merges.txt (deflated 60%)\n",
            "  adding: dreambooth-out1/tokenizer/special_tokens_map.json (deflated 72%)\n",
            "  adding: dreambooth-out1/tokenizer/tokenizer_config.json (deflated 68%)\n",
            "  adding: dreambooth-out1/tokenizer/vocab.json (deflated 71%)\n",
            "  adding: dreambooth-out1/unet/ (stored 0%)\n",
            "  adding: dreambooth-out1/unet/config.json (deflated 66%)\n",
            "  adding: dreambooth-out1/unet/diffusion_pytorch_model.safetensors (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('dreambooth-out1.zip')"
      ],
      "metadata": {
        "id": "OZITQnTIefLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/DL_Project/dreambooth-out1.zip ./dreambooth-out1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBpy_JC-hWKz",
        "outputId": "598c0d5a-1bb2-4afe-8deb-5e9b44644173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: dreambooth-out1/ (stored 0%)\n",
            "  adding: dreambooth-out1/scheduler/ (stored 0%)\n",
            "  adding: dreambooth-out1/scheduler/scheduler_config.json (deflated 41%)\n",
            "  adding: dreambooth-out1/text_encoder/ (stored 0%)\n",
            "  adding: dreambooth-out1/text_encoder/config.json (deflated 45%)\n",
            "  adding: dreambooth-out1/text_encoder/model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/feature_extractor/ (stored 0%)\n",
            "  adding: dreambooth-out1/feature_extractor/preprocessor_config.json (deflated 49%)\n",
            "  adding: dreambooth-out1/checkpoint-500/ (stored 0%)\n",
            "  adding: dreambooth-out1/checkpoint-500/text_encoder/ (stored 0%)\n",
            "  adding: dreambooth-out1/checkpoint-500/text_encoder/config.json (deflated 45%)\n",
            "  adding: dreambooth-out1/checkpoint-500/text_encoder/model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/checkpoint-500/optimizer.bin (deflated 22%)\n",
            "  adding: dreambooth-out1/checkpoint-500/scheduler.bin (deflated 55%)\n",
            "  adding: dreambooth-out1/checkpoint-500/unet/ (stored 0%)\n",
            "  adding: dreambooth-out1/checkpoint-500/unet/config.json (deflated 66%)\n",
            "  adding: dreambooth-out1/checkpoint-500/unet/diffusion_pytorch_model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/checkpoint-500/random_states_0.pkl (deflated 25%)\n",
            "  adding: dreambooth-out1/vae/ (stored 0%)\n",
            "  adding: dreambooth-out1/vae/config.json (deflated 53%)\n",
            "  adding: dreambooth-out1/vae/diffusion_pytorch_model.safetensors (deflated 7%)\n",
            "  adding: dreambooth-out1/logs/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5915463/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5915463/events.out.tfevents.1702825463.cf7b68bcd47c.7904.1 (deflated 56%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5935092/ (stored 0%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/1702825463.5935092/hparams.yml (deflated 52%)\n",
            "  adding: dreambooth-out1/logs/dreambooth/events.out.tfevents.1702825463.cf7b68bcd47c.7904.0 (deflated 66%)\n",
            "  adding: dreambooth-out1/model_index.json (deflated 56%)\n",
            "  adding: dreambooth-out1/tokenizer/ (stored 0%)\n",
            "  adding: dreambooth-out1/tokenizer/merges.txt (deflated 60%)\n",
            "  adding: dreambooth-out1/tokenizer/special_tokens_map.json (deflated 72%)\n",
            "  adding: dreambooth-out1/tokenizer/tokenizer_config.json (deflated 68%)\n",
            "  adding: dreambooth-out1/tokenizer/vocab.json (deflated 71%)\n",
            "  adding: dreambooth-out1/unet/ (stored 0%)\n",
            "  adding: dreambooth-out1/unet/config.json (deflated 66%)\n",
            "  adding: dreambooth-out1/unet/diffusion_pytorch_model.safetensors (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./dreambooth-out1/ /content/drive/MyDrive/DL_Project/"
      ],
      "metadata": {
        "id": "MjqhCRGWmptm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pushing to Huggingface"
      ],
      "metadata": {
        "id": "hLru2ulNvrz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZefGxC3_rOJC",
        "outputId": "c8b055a2-72e8-407e-e2cc-1c34f929872a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d1c_glotLhE",
        "outputId": "5f1fe406-2161-47ac-e507-fa06ecc22804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository\n",
        "repo = Repository(local_dir=\"SD_2.0_DreamBooth_DragonWarrior\", clone_from=\"Bilal326/SD_2.0_DreamBooth_DragonWarrior\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ojVUXWctPa1",
        "outputId": "0b802656-3c0f-479a-a7de-4803bfc29138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/Bilal326/SD_2.0_DreamBooth_DragonWarrior into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Bilal326/SD_2.0_DreamBooth_DragonWarrior into local empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/DL_Project/dreambooth-out1 ./SD_2.0_DreamBooth_DragonWarrior/"
      ],
      "metadata": {
        "id": "afumU_2utl-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SD_2.0_DreamBooth_DragonWarrior\n",
        "!git add .\n",
        "!git commit -m \"Initial commit dreambooth-out1 kungfupanda po\"\n",
        "!git push origin main --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMAGh_htv3O",
        "outputId": "a446beba-acf1-4834-a636-b021e469ef93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'SD_2.0_DreamBooth_DragonWarrior'\n",
            "/content/SD_2.0_DreamBooth_DragonWarrior\n",
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Uploading LFS objects: 100% (10/10), 12 GB | 0 B/s, done.\n",
            "Enumerating objects: 41, done.\n",
            "Counting objects: 100% (41/41), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (37/37), done.\n",
            "Writing objects: 100% (41/41), 517.85 KiB | 4.71 MiB/s, done.\n",
            "Total 41 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "To https://huggingface.co/Bilal326/SD_2.0_DreamBooth_DragonWarrior\n",
            " + 300c262...ead254b main -> main (forced update)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsJVeoCBuyVP",
        "outputId": "dda4db82-10ff-4329-9830-d87a53a97962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SD_2.0_DreamBooth_DragonWarrior\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv dreambooth-out1/* ."
      ],
      "metadata": {
        "id": "iMTC0ot91eNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SD_2.0_DreamBooth_DragonWarrior\n",
        "!git add .\n",
        "!git commit -m \"Initial commit dreambooth-out1 kungfupanda po\"\n",
        "!git push origin main --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTVZY8bJ1mlz",
        "outputId": "848ac49a-6222-48cf-9e95-ca1298320453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'SD_2.0_DreamBooth_DragonWarrior'\n",
            "/content/SD_2.0_DreamBooth_DragonWarrior\n",
            "[main 42b91d6] Initial commit dreambooth-out1 kungfupanda po\n",
            " 23 files changed, 0 insertions(+), 0 deletions(-)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/optimizer.bin (100%)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/random_states_0.pkl (100%)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/scheduler.bin (100%)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/text_encoder/config.json (100%)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/text_encoder/model.safetensors (100%)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/unet/config.json (100%)\n",
            " rename {dreambooth-out1/checkpoint-500 => checkpoint-500}/unet/diffusion_pytorch_model.safetensors (100%)\n",
            " rename {dreambooth-out1/feature_extractor => feature_extractor}/preprocessor_config.json (100%)\n",
            " rename {dreambooth-out1/logs => logs}/dreambooth/1702825463.5915463/events.out.tfevents.1702825463.cf7b68bcd47c.7904.1 (100%)\n",
            " rename {dreambooth-out1/logs => logs}/dreambooth/1702825463.5935092/hparams.yml (100%)\n",
            " rename {dreambooth-out1/logs => logs}/dreambooth/events.out.tfevents.1702825463.cf7b68bcd47c.7904.0 (100%)\n",
            " rename dreambooth-out1/model_index.json => model_index.json (100%)\n",
            " rename {dreambooth-out1/scheduler => scheduler}/scheduler_config.json (100%)\n",
            " rename {dreambooth-out1/text_encoder => text_encoder}/config.json (100%)\n",
            " rename {dreambooth-out1/text_encoder => text_encoder}/model.safetensors (100%)\n",
            " rename {dreambooth-out1/tokenizer => tokenizer}/merges.txt (100%)\n",
            " rename {dreambooth-out1/tokenizer => tokenizer}/special_tokens_map.json (100%)\n",
            " rename {dreambooth-out1/tokenizer => tokenizer}/tokenizer_config.json (100%)\n",
            " rename {dreambooth-out1/tokenizer => tokenizer}/vocab.json (100%)\n",
            " rename {dreambooth-out1/unet => unet}/config.json (100%)\n",
            " rename {dreambooth-out1/unet => unet}/diffusion_pytorch_model.safetensors (100%)\n",
            " rename {dreambooth-out1/vae => vae}/config.json (100%)\n",
            " rename {dreambooth-out1/vae => vae}/diffusion_pytorch_model.safetensors (100%)\n",
            "Enumerating objects: 37, done.\n",
            "Counting objects: 100% (37/37), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (33/33), done.\n",
            "Writing objects: 100% (36/36), 517.40 KiB | 4.66 MiB/s, done.\n",
            "Total 36 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "To https://huggingface.co/Bilal326/SD_2.0_DreamBooth_DragonWarrior\n",
            "   ead254b..42b91d6  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoNKfHb4136y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}